{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 20:49:56.812707: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-11-28 20:49:56.812741: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-28 20:49:56.812750: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-28 20:49:56.812826: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-28 20:49:56.812874: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Hardware Reference Model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-28 20:49:57.390456: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 10s 5ms/step - loss: 0.3789 - accuracy: 0.8924 - val_loss: 0.2576 - val_accuracy: 0.9263\n",
      "Epoch 2/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3198 - accuracy: 0.9107 - val_loss: 0.2551 - val_accuracy: 0.9302\n",
      "Epoch 3/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3223 - accuracy: 0.9110 - val_loss: 0.2970 - val_accuracy: 0.9200\n",
      "Epoch 4/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3276 - accuracy: 0.9101 - val_loss: 0.2797 - val_accuracy: 0.9228\n",
      "Epoch 5/5\n",
      "1688/1688 [==============================] - 8s 5ms/step - loss: 0.3403 - accuracy: 0.9084 - val_loss: 0.2832 - val_accuracy: 0.9263\n",
      "\n",
      "Final Test Accuracy: 91.48% (Target: >95%)\n",
      "\n",
      "Exporting Weights to 'model_data/'...\n",
      " -> Saved layer1: Weights (784, 128), Biases (128,)\n",
      " -> Saved output: Weights (128, 10), Biases (10,)\n",
      "\n",
      "DONE. These CSV files are the 'brains' you will give to your C++ accelerator.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# PART 1: PRE-PROCESSING (HARDWARE ALIGNMENT)\n",
    "# ==========================================\n",
    "# We flatten the 2D images (28x28) into 1D vectors (784).\n",
    "# This aligns with the memory layout of our simple matrix multiplication accelerator.\n",
    "# Normalization (0-255 -> 0.0-1.0) is performed to stabilize gradients during training.\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape: [60000, 28, 28] -> [60000, 784]\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "print(f\"[Pre-processing] Training Data Shape: {x_train.shape}\")\n",
    "print(f\"[Pre-processing] Test Data Shape:     {x_test.shape}\")\n",
    "\n",
    "# ==========================================\n",
    "# PART 2: MODEL ARCHITECTURE DEFINITION\n",
    "# ==========================================\n",
    "# Architecture: Multi-Layer Perceptron (MLP)\n",
    "# Rationale: Chosen over CNNs for this project to simplify the hardware implementation.\n",
    "# The core operation is Matrix-Vector Multiplication (GEMV), which we will simulate in C++.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  # Input Layer: Accepts the flattened 784-element vector\n",
    "  tf.keras.Input(shape=(784,)),\n",
    "  \n",
    "  # Hidden Layer 1: 128 Neurons with ReLU activation.\n",
    "  # Hardware Op: (Input x Weights_1) + Bias_1 -> ReLU\n",
    "  tf.keras.layers.Dense(128, activation='relu', name='layer1'),\n",
    "  \n",
    "  # Output Layer: 10 Neurons (one for each digit 0-9) with Softmax.\n",
    "  # Hardware Op: (Hidden_1 x Weights_Out) + Bias_Out -> Softmax\n",
    "  tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ==========================================\n",
    "# PART 3: TRAINING (GENERATING GOLDEN REFERENCE)\n",
    "# ==========================================\n",
    "# Training the model on the M3 GPU to generate the \"Golden\" weights.\n",
    "# The accuracy achieved here serves as the benchmark for our hardware simulation.\n",
    "\n",
    "print(\"\\n[Training] Starting training run...\")\n",
    "history = model.fit(x_train, y_train, epochs=5, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Evaluation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'\\n[Evaluation] Final Test Accuracy: {test_acc*100:.2f}%')\n",
    "\n",
    "# ==========================================\n",
    "# PART 4: WEIGHT EXPORT (SERIALIZATION)\n",
    "# ==========================================\n",
    "# Critical Step: Exporting the trained parameters (Weights and Biases) to CSV.\n",
    "# These files will serve as the \"ROM\" (Read-Only Memory) for our C++ simulator.\n",
    "# The simulator will read these values to perform inference without TensorFlow.\n",
    "\n",
    "weights_dir = 'model_data'\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n[Export] Saving parameters to './{weights_dir}/'...\")\n",
    "\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'get_weights'):\n",
    "        w, b = layer.get_weights()\n",
    "        \n",
    "        # Save Weights (Connections between layers)\n",
    "        w_path = os.path.join(weights_dir, f'{layer.name}_weights.csv')\n",
    "        np.savetxt(w_path, w, delimiter=',')\n",
    "        \n",
    "        # Save Biases (Activation thresholds)\n",
    "        b_path = os.path.join(weights_dir, f'{layer.name}_biases.csv')\n",
    "        np.savetxt(b_path, b, delimiter=',')\n",
    "        \n",
    "        print(f\" -> Exported {layer.name}: Weights Shape {w.shape}, Biases Shape {b.shape}\")\n",
    "\n",
    "print(\"\\n[Success] Weights exported. Ready for C++ integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee838fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
